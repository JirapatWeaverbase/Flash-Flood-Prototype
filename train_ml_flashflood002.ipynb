{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "680dd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, mean_absolute_error, r2_score\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e90ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1548 rows\n",
      "Date range: 2024-06-10 13:00:00 to 2024-10-01 22:15:00\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 1. LOAD DATA\n",
    "# =====================\n",
    "df = pd.read_csv(\"flash_flood_with_labels.csv\")\n",
    "\n",
    "# แปลง timestamp เป็น datetime (รองรับหลายรูปแบบ)\n",
    "try:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%d/%m/%Y %H:%M')\n",
    "except:\n",
    "    try:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], format='%m/%d/%Y %H:%M')\n",
    "    except:\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True)\n",
    "\n",
    "print(f\"Loaded {len(df)} rows\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c1201a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 39 features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boatd\\AppData\\Local\\Temp\\ipykernel_7060\\3233268443.py:26: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df = df.fillna(method='bfill').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "for window in [3, 6, 9]:\n",
    "    df[f'rain_sum_{window}'] = df.groupby('sensor_id')['rainfall_mm_per_hr'].rolling(window=window, min_periods=1).sum().reset_index(level=0, drop=True)\n",
    "    df[f'rain_std_{window}'] = df.groupby('sensor_id')['rainfall_mm_per_hr'].rolling(window=window, min_periods=1).std().reset_index(level=0, drop=True)\n",
    "    df[f'flow_max_{window}'] = df.groupby('sensor_id')['water_flow_rate_m3_per_sec'].rolling(window=window, min_periods=1).max().reset_index(level=0, drop=True)\n",
    "    df[f'vibration_mean_{window}'] = df.groupby('sensor_id')['vibration_magnitude'].rolling(window=window, min_periods=1).mean().reset_index(level=0, drop=True)\n",
    "\n",
    "# Rate of change (อัตราการเปลี่ยนแปลง)\n",
    "df['rain_change'] = df.groupby('sensor_id')['rainfall_mm_per_hr'].diff()\n",
    "df['flow_change'] = df.groupby('sensor_id')['water_flow_rate_m3_per_sec'].diff()\n",
    "df['vibration_change'] = df.groupby('sensor_id')['vibration_magnitude'].diff()\n",
    "\n",
    "# Lag features (ค่าจากช่วงเวลาก่อนหน้า)\n",
    "for col in ['rainfall_mm_per_hr', 'water_flow_rate_m3_per_sec', 'vibration_magnitude']:\n",
    "    df[f'{col}_lag1'] = df.groupby('sensor_id')[col].shift(1)\n",
    "    df[f'{col}_lag2'] = df.groupby('sensor_id')[col].shift(2)\n",
    "\n",
    "# Interaction features\n",
    "df['rain_flow_interaction'] = df['rainfall_mm_per_hr'] * df['water_flow_rate_m3_per_sec']\n",
    "df['rain_vibration_interaction'] = df['rainfall_mm_per_hr'] * df['vibration_magnitude']\n",
    "\n",
    "# Sensor-specific features\n",
    "df['sensor_upstream'] = (df['sensor_name'] == 'Upper').astype(int)\n",
    "df['sensor_midstream'] = (df['sensor_name'] == 'Middle').astype(int)\n",
    "\n",
    "# Handle missing values from lag/diff operations\n",
    "df = df.fillna(method='bfill').fillna(0)\n",
    "\n",
    "print(f\"Created {len(df.columns)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c834f822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Split:\n",
      "Train: (1083, 33), Val: (234, 33), Test: (231, 33)\n",
      "Train flood ratio: 70.08%\n",
      "\n",
      "Class distributions:\n",
      "Train: {1: 759, 0: 324}\n",
      "Val:   {1: 234}\n",
      "Test:  {1: 231}\n",
      "\n",
      "Warning: One or more temporal splits contain only a single class. Falling back to stratified random split.\n",
      "New splits (stratified):\n",
      "Train: (1082, 33), Val: (233, 33), Test: (233, 33)\n",
      "Train flood ratio: 0.7911275415896488\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 3. PREPARE DATASETS\n",
    "# =====================\n",
    "# Define feature columns (exclude timestamp, IDs, and target)\n",
    "feature_cols = [col for col in df.columns if col not in \n",
    "                ['timestamp', 'sensor_id', 'sensor_name', 'event_intensity', \n",
    "                 'is_flash_flood', 'time_to_next_sensor_min']]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y_classification = df['is_flash_flood']\n",
    "\n",
    "# For regression, only use rows with valid time_to_next_sensor\n",
    "df_reg = df[df['time_to_next_sensor_min'].notna()].copy()\n",
    "X_reg = df_reg[feature_cols]\n",
    "y_reg = df_reg['time_to_next_sensor_min']\n",
    "\n",
    "# Temporal split (70% train, 15% val, 15% test)\n",
    "split_date_1 = df['timestamp'].quantile(0.70)\n",
    "split_date_2 = df['timestamp'].quantile(0.85)\n",
    "\n",
    "train_mask = df['timestamp'] <= split_date_1\n",
    "val_mask = (df['timestamp'] > split_date_1) & (df['timestamp'] <= split_date_2)\n",
    "test_mask = df['timestamp'] > split_date_2\n",
    "\n",
    "X_train = X[train_mask]\n",
    "X_val = X[val_mask]\n",
    "X_test = X[test_mask]\n",
    "\n",
    "y_train = y_classification[train_mask]\n",
    "y_val = y_classification[val_mask]\n",
    "y_test = y_classification[test_mask]\n",
    "\n",
    "print(f\"\\nClassification Split:\")\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "print(f\"Train flood ratio: {y_train.mean():.2%}\")\n",
    "\n",
    "\n",
    "# Quick checks: class distribution in each split\n",
    "print(\"\\nClass distributions:\")\n",
    "print(\"Train:\", y_train.value_counts(dropna=False).to_dict())\n",
    "print(\"Val:  \", y_val.value_counts(dropna=False).to_dict())\n",
    "print(\"Test: \", y_test.value_counts(dropna=False).to_dict())\n",
    "\n",
    "# If any split contains only one class, fallback to stratified random split\n",
    "if len(y_train.unique()) < 2 or len(y_val.unique()) < 2 or len(y_test.unique()) < 2:\n",
    "    print(\"\\nWarning: One or more temporal splits contain only a single class. Falling back to stratified random split.\")\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y_classification, test_size=0.15, stratify=y_classification, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1764705882, stratify=y_temp, random_state=42)  # 0.17647*0.85 ≈ 0.15 overall\n",
    "    print(\"New splits (stratified):\")\n",
    "    print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "    print(\"Train flood ratio:\", y_train.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea8f819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING CLASSIFICATION MODEL\n",
      "==================================================\n",
      "\n",
      "Training RandomForest...\n",
      "RandomForest - ROC AUC: 1.0000\n",
      "\n",
      "Training GradientBoosting...\n",
      "GradientBoosting - ROC AUC: 1.0000\n",
      "\n",
      "Best model: RandomForest (ROC AUC: 1.0000)\n",
      "\n",
      "==================================================\n",
      "FINAL TEST SET RESULTS - CLASSIFICATION\n",
      "==================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        49\n",
      "           1       1.00      1.00      1.00       184\n",
      "\n",
      "    accuracy                           1.00       233\n",
      "   macro avg       1.00      1.00      1.00       233\n",
      "weighted avg       1.00      1.00      1.00       233\n",
      "\n",
      "ROC AUC: 1.0000\n",
      "ROC AUC: 1.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 49   0]\n",
      " [  0 184]]\n",
      "\n",
      "Top 10 Most Important Features:\n",
      "                feature  importance\n",
      "7                 month    0.390366\n",
      "6           day_of_week    0.103553\n",
      "19     vibration_mean_9    0.081419\n",
      "5                  hour    0.062518\n",
      "15     vibration_mean_6    0.061518\n",
      "17           rain_std_9    0.045187\n",
      "11     vibration_mean_3    0.037844\n",
      "18           flow_max_9    0.036101\n",
      "13           rain_std_6    0.033074\n",
      "4   vibration_magnitude    0.022401\n",
      "\n",
      "Saved model: flash_flood_classifier.pkl\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 4. TRAIN CLASSIFICATION MODEL\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING CLASSIFICATION MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Try multiple models\n",
    "\n",
    "best_model_name = None\n",
    "best_score = -1\n",
    "models = {\n",
    "    'RandomForest': RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=20,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'GradientBoosting': GradientBoostingClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_model_name = None \n",
    "best_score = -1\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Validation\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_val_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    # Compute ROC AUC only if validation has both classes and model provides probabilities\n",
    "    if y_val_proba is not None and len(np.unique(y_val)) == 2:\n",
    "        roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "        print(f\"{name} - ROC AUC: {roc_auc:.4f}\")\n",
    "    else:\n",
    "        roc_auc = np.nan\n",
    "        print(f\"{name} - ROC AUC: nan (validation set does not contain both classes or model has no predict_proba)\")\n",
    "    \n",
    "    # roc_auc = roc_auc_score(y_val, y_val_proba)\n",
    "    # print(f\"{name} - ROC AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    if roc_auc > best_score or best_model is None:\n",
    "        best_score = roc_auc\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} (ROC AUC: {best_score:.4f})\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "if hasattr(best_model, \"predict_proba\"):\n",
    "    y_test_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL TEST SET RESULTS - CLASSIFICATION\")\n",
    "print(\"=\"*50)\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(f\"ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "\n",
    "if y_test_proba is not None and len(np.unique(y_test)) == 2:\n",
    "    print(f\"ROC AUC: {roc_auc_score(y_test, y_test_proba):.4f}\")\n",
    "else:\n",
    "    print(\"ROC AUC: nan (test set does not contain both classes or model has no predict_proba)\")\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "joblib.dump(best_model, 'flash_flood_classifier.pkl')\n",
    "print(\"\\nSaved model: flash_flood_classifier.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30fb0837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "TRAINING REGRESSION MODEL\n",
      "==================================================\n",
      "Regression Split:\n",
      "Train: (1083, 33), Val: (234, 33), Test: (231, 33)\n",
      "\n",
      "Validation - MAE: 2.27 min, R²: -9.0192\n",
      "\n",
      "==================================================\n",
      "FINAL TEST SET RESULTS - REGRESSION\n",
      "==================================================\n",
      "MAE: 1.45 minutes\n",
      "R²: -21.1575\n",
      "RMSE: 1.55 minutes\n",
      "\n",
      "Saved model: flash_flood_time_regressor.pkl\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 5. TRAIN REGRESSION MODEL (Time to Next Sensor)\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING REGRESSION MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Temporal split for regression data\n",
    "train_mask_reg = df_reg['timestamp'] <= split_date_1\n",
    "val_mask_reg = (df_reg['timestamp'] > split_date_1) & (df_reg['timestamp'] <= split_date_2)\n",
    "test_mask_reg = df_reg['timestamp'] > split_date_2\n",
    "\n",
    "X_train_reg = X_reg[train_mask_reg]\n",
    "X_val_reg = X_reg[val_mask_reg]\n",
    "X_test_reg = X_reg[test_mask_reg]\n",
    "\n",
    "y_train_reg = y_reg[train_mask_reg]\n",
    "y_val_reg = y_reg[val_mask_reg]\n",
    "y_test_reg = y_reg[test_mask_reg]\n",
    "\n",
    "print(f\"Regression Split:\")\n",
    "print(f\"Train: {X_train_reg.shape}, Val: {X_val_reg.shape}, Test: {X_test_reg.shape}\")\n",
    "\n",
    "# Train regression model\n",
    "reg_model = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=10,\n",
    "    min_samples_split=15,\n",
    "    min_samples_leaf=10,\n",
    "    max_features='sqrt',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "reg_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Validation\n",
    "y_val_reg_pred = reg_model.predict(X_val_reg)\n",
    "val_mae = mean_absolute_error(y_val_reg, y_val_reg_pred)\n",
    "val_r2 = r2_score(y_val_reg, y_val_reg_pred)\n",
    "print(f\"\\nValidation - MAE: {val_mae:.2f} min, R²: {val_r2:.4f}\")\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_reg_pred = reg_model.predict(X_test_reg)\n",
    "test_mae = mean_absolute_error(y_test_reg, y_test_reg_pred)\n",
    "test_r2 = r2_score(y_test_reg, y_test_reg_pred)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL TEST SET RESULTS - REGRESSION\")\n",
    "print(\"=\"*50)\n",
    "print(f\"MAE: {test_mae:.2f} minutes\")\n",
    "print(f\"R²: {test_r2:.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(np.mean((y_test_reg - y_test_reg_pred)**2)):.2f} minutes\")\n",
    "joblib.dump(reg_model, 'flash_flood_time_regressor.pkl')\n",
    "print(\"\\nSaved model: flash_flood_time_regressor.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "edb7b21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "INFERENCE EXAMPLE\n",
      "==================================================\n",
      "Location: Upper sensor\n",
      "Flash Flood Prediction: NO (Probability: 11.05%)\n",
      "\n",
      "==================================================\n",
      "DONE!\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# =====================\n",
    "# 6. INFERENCE EXAMPLE\n",
    "# =====================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INFERENCE EXAMPLE\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Take a sample from test set\n",
    "# sample = X_test.iloc[0:1]\n",
    "# flood_prob = best_model.predict_proba(sample)[0, 1]\n",
    "# flood_pred = \"YES\" if flood_prob > 0.5 else \"NO\"\n",
    "\n",
    "sample_idx = 0\n",
    "sample = X_test.iloc[sample_idx:sample_idx+1]\n",
    "sensor_name = df.loc[sample.index[0], 'sensor_name']\n",
    "\n",
    "flood_prob = best_model.predict_proba(sample)[0, 1]\n",
    "flood_pred = \"YES\" if flood_prob > 0.5 else \"NO\"\n",
    "\n",
    "print(f\"Location: {sensor_name} sensor\")\n",
    "print(f\"Flash Flood Prediction: {flood_pred} (Probability: {flood_prob:.2%})\")\n",
    "\n",
    "# If flood predicted and sample has next sensor info, predict time\n",
    "if flood_pred == \"YES\" and test_mask_reg.iloc[sample_idx]:\n",
    "    sample_reg = X_reg[test_mask_reg].iloc[sample_idx:sample_idx+1]\n",
    "    next_sensor = \"Middle\" if sensor_name == \"Upper\" else \"Lower\"\n",
    "    time_pred = reg_model.predict(sample_reg)[0]\n",
    "    print(f\"Estimated Time to {next_sensor} Sensor: {time_pred:.1f} minutes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DONE!\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
